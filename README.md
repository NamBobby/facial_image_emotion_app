# Facial Emotion Recognition System 

A comprehensive end-to-end system that detects faces using **YOLOv8** and classifies facial expressions using a custom-trained **InceptionV3** model. This application provides a real-time analysis pipeline with a step-by-step visualization of image processing, developed as part of our coursework to demonstrate practical applications of computer vision.

---

## üìë Project Report & Documentation

Detailed documentation regarding the methodology, experiments, and results can be found here:

* **[üìú Final Project Report (PDF)](https://www.google.com/search?q=YOUR_LINK_TO_REPORT_HERE)**

---

## üë• Group Members - Class MSA34HCM

| No. | Name | Student ID |
| --- | --- | --- |
| 1 | **V√µ H·∫°nh T√¢n** | 25MS23260 |
| 2 | **L√™ Thanh Ph∆∞∆°ng Nam** | 25MS23308 |
| 3 | **Tr·∫ßn Qu·∫ø T·ª≠** | 25MS23291 |
| 4 | **ƒêinh Tr·∫ßn Qu·ªëc Tu·∫•n** | 25MS23309 |
| 5 | **Tr·∫ßn Vi·ªát Ph√∫c** | 25MS23272 |

## üì∫ Demo Video

Uploading DEMO-2-2.mp4‚Ä¶

---

## üìÇ Project Structure

```text
facial_image_emotion_app/
‚îú‚îÄ‚îÄ jupyter_notebooks/                                  # Model Development (Not for production)
‚îÇ   ‚îú‚îÄ‚îÄ ivp501-emotion-preprocessing.ipynb              # Image processing pipeline development
‚îÇ   ‚îú‚îÄ‚îÄ ivp501-inceptionv3-emotion-training.ipynb       # InceptionV3 model training
‚îÇ   ‚îî‚îÄ‚îÄ ivp501-experiment-final.ipynb                   # Model evaluation and experiments
‚îú‚îÄ‚îÄ streamlit/                  # Production Web Application
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # AI Weights & Configurations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model_processed.pth
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ class_indices.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolov8n-face.pt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ service.py          # Core AI logic & Image Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ ui/                     # UI Components & Screens
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ screens/            # Home, Shooting, and Result screens
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/             # Global CSS styles
‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Main entry point
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                # Helper functions
‚îî‚îÄ‚îÄ README.md

```

---

## üß™ Model Development (Jupyter Notebooks)

The `jupyter_notebooks` folder contains the full research and training process.

> **Note:** These files are for educational and reference purposes to understand how the model was built; they are **not** required to run the web application.

1. **Preprocessing Notebook:** [View on Kaggle/Link](https://www.kaggle.com/code/namle25/ivp501-emotion-preprocessing) - Focuses on CLAHE, Bilateral Filtering, and Sharpening techniques.
2. **Training Notebook:** [View on Kaggle/Link](https://www.kaggle.com/code/nabby25/ivp501-inceptionv3-emotion-training) - Two-stage training (Transfer Learning + Fine-tuning) using InceptionV3.
3. **Experiment Notebook:** [View on Kaggle/Link](https://www.kaggle.com/code/dinhtranquoctuan/ivp501-experiment-final) - Comparative analysis between raw dataset and processed dataset performance.

---

## üõ†Ô∏è Installation & Setup

### 1. Navigate to directory

```bash
cd streamlit

```

### 2. Create Virtual Environment

* **Windows:** `python -m venv venv`
* **macOS/Linux:** `python3 -m venv venv`

### 3. Activate Environment

* **Windows:** `.\venv\Scripts\activate`
* **macOS/Linux:** `source venv/bin/activate`

### 4. Install & Run

```bash
pip install -r requirements.txt
streamlit run app.py

```

Once successful, your browser will automatically open the app at `http://localhost:8501`.

---

## üîç Analysis Pipeline Visualization

The application features a dedicated **Analysis Tab** that reveals the internal "thinking" process of the AI:

* **Step 1:** Face Detection via YOLOv8.
* **Step 2:** Grayscale Conversion.
* **Step 3:** Bilateral Denoising.
* **Step 4:** CLAHE (Contrast Enhancement).
* **Step 5:** Unsharp Masking (Sharpening).

---

## üìù Requirements

* Python 3.9+
* Webcam (for live capture)
* Stable internet connection 
